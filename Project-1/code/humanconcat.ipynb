{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAcc = 0.0\n",
    "maxIter = 0\n",
    "C_Lambda = 0.8\n",
    "TrainingPercent = 80\n",
    "ValidationPercent = 10\n",
    "TestPercent = 10\n",
    "PHI = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     img_id_A img_id_B  f1_x  f2_x  f3_x  f4_x  f5_x  f6_x  f7_x  f8_x  \\\n",
      "0       1219b    1219c     2     0     1     0     2     1     0     3   \n",
      "1       1197a    1197c     1     4     1     3     0     2     1     0   \n",
      "2       1543a    1562b     3     1     1     0     2     2     0     4   \n",
      "3       1329b    1329c     1     1     1     3     2     2     3     0   \n",
      "4       0451a    1325c     2     1     1     0     2     1     0     0   \n",
      "5       1499b    1499c     2     1     1     2     2     2     3     4   \n",
      "6       1204a    1521c     0     0     1     0     2     2     1     0   \n",
      "7       1432b    1140a     3     1     1     0     1     2     1     4   \n",
      "8       0969a    0535b     2     2     1     1     2     2     1     2   \n",
      "9       1240a    0374a     1     0     1     3     2     2     3     1   \n",
      "10      0349b    1450c     0     1     1     3     2     2     3     1   \n",
      "11      1424a    0327c     3     4     1     0     2     2     1     2   \n",
      "12      0314c    0314a     1     1     1     3     2     0     0     0   \n",
      "13      1545a    1450b     0     1     1     0     2     2     1     2   \n",
      "14      0338b    0338a     2     1     1     3     2     1     0     3   \n",
      "15      0593b    1367b     3     4     1     0     2     2     3     3   \n",
      "16      1408c    1164b     0     1     1     0     0     2     0     2   \n",
      "17      0552a    1442a     2     1     1     0     2     2     1     2   \n",
      "18      0354b    1417b     3     1     1     0     2     3     1     4   \n",
      "19      0550a    1441c     3     4     1     3     2     2     0     0   \n",
      "20      0539a    0539c     2     4     1     3     2     2     1     2   \n",
      "21      0571a    1547a     2     4     1     3     2     3     0     1   \n",
      "22      0536b    0340a     1     0     1     2     2     2     0     3   \n",
      "23      0359b    0440b     3     2     1     0     2     2     3     0   \n",
      "24      1521b    0352c     3     1     1     3     0     2     3     3   \n",
      "25      1517a    1149b     2     1     1     1     2     2     0     2   \n",
      "26      0459b    0549c     2     0     1     0     2     3     1     3   \n",
      "27      1373a    1194c     3     4     1     3     2     2     2     1   \n",
      "28      1461b    1122a     2     2     1     0     2     1     0     0   \n",
      "29      0570a    1392a     2     1     0     3     0     2     1     3   \n",
      "...       ...      ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
      "2606    0372b    1377a     1     1     1     3     1     2     1     2   \n",
      "2607    1257a    1521b     2     1     1     2     2     1     0     3   \n",
      "2608    0597c    0593b     1     4     1     0     2     2     1     1   \n",
      "2609    1545a    0471a     0     1     1     0     2     2     1     2   \n",
      "2610    1378b    1416a     3     1     1     3     2     2     1     3   \n",
      "2611    1307b    0938b     3     4     1     0     2     3     1     1   \n",
      "2612    1119a    1413a     1     1     1     0     0     2     0     1   \n",
      "2613    1440b    0302b     0     4     0     2     0     2     0     4   \n",
      "2614    1180b    1325a     1     1     1     0     2     2     1     1   \n",
      "2615    1520a    1520c     3     2     1     3     2     2     0     2   \n",
      "2616    0594a    1496a     3     2     1     0     2     2     1     4   \n",
      "2617    0571c    0375b     1     0     1     1     0     1     0     1   \n",
      "2618    0431c    1494c     2     0     1     0     2     2     2     3   \n",
      "2619    0306a    1448a     3     1     1     2     2     2     0     1   \n",
      "2620    0338a    1366c     2     4     1     0     2     3     0     1   \n",
      "2621    1565a    1255a     2     4     1     3     2     2     0     1   \n",
      "2622    1370a    1370c     2     1     1     3     0     2     0     1   \n",
      "2623    1533b    1533c     1     0     1     0     2     3     0     4   \n",
      "2624    1507b    0488b     1     0     1     1     2     2     3     0   \n",
      "2625    0560c    1134b     1     1     1     0     2     1     1     0   \n",
      "2626    1458a    1330c     0     1     1     3     2     2     1     1   \n",
      "2627    0539a    1252a     2     4     1     3     2     2     1     2   \n",
      "2628    1446a    1468c     1     1     1     3     2     2     1     2   \n",
      "2629    1227b    1485c     3     1     1     3     2     1     0     4   \n",
      "2630    1284a    1284c     2     1     1     0     2     2     1     4   \n",
      "2631    0483a    1197c     2     2     1     3     2     2     0     1   \n",
      "2632    0381b    0381c     3     1     1     0     2     3     0     4   \n",
      "2633    1271b    1271c     3     4     2     2     0     2     1     3   \n",
      "2634    1481a    1481b     3     1     1     1     2     2     0     3   \n",
      "2635    0592c    1406c     1     2     1     1     2     3     0     3   \n",
      "\n",
      "         ...      f1_y  f2_y  f3_y  f4_y  f5_y  f6_y  f7_y  f8_y  f9_y  \\\n",
      "0        ...         2     4     0     1     2     3     0     1     2   \n",
      "1        ...         1     2     1     0     0     2     0     4     2   \n",
      "2        ...         1     2     1     0     0     2     0     2     2   \n",
      "3        ...         0     1     1     0     2     2     3     0     2   \n",
      "4        ...         1     4     1     3     2     3     1     2     2   \n",
      "5        ...         2     0     1     3     0     2     1     3     2   \n",
      "6        ...         0     1     1     2     2     2     1     0     2   \n",
      "7        ...         3     4     0     2     2     1     1     3     2   \n",
      "8        ...         0     0     1     2     2     2     1     4     2   \n",
      "9        ...         2     2     0     0     2     1     3     3     2   \n",
      "10       ...         3     0     1     1     2     1     1     3     2   \n",
      "11       ...         1     1     1     1     2     1     1     2     1   \n",
      "12       ...         1     1     1     0     2     1     2     1     1   \n",
      "13       ...         2     2     1     3     2     3     0     3     2   \n",
      "14       ...         2     4     1     0     2     3     0     1     2   \n",
      "15       ...         1     1     0     1     2     1     0     3     2   \n",
      "16       ...         2     1     1     2     1     2     1     1     2   \n",
      "17       ...         3     2     1     0     2     2     0     1     2   \n",
      "18       ...         3     4     1     0     2     3     0     3     2   \n",
      "19       ...         1     1     1     1     2     2     1     1     1   \n",
      "20       ...         2     1     1     0     2     2     3     0     2   \n",
      "21       ...         2     4     1     1     2     1     0     2     2   \n",
      "22       ...         3     0     1     0     2     3     1     2     2   \n",
      "23       ...         2     1     1     2     0     2     1     0     1   \n",
      "24       ...         3     4     1     1     2     3     1     3     2   \n",
      "25       ...         2     4     1     3     2     2     1     0     2   \n",
      "26       ...         3     1     1     3     3     3     3     4     2   \n",
      "27       ...         2     1     2     1     2     2     0     3     2   \n",
      "28       ...         2     1     1     3     0     1     0     2     1   \n",
      "29       ...         2     4     1     1     0     2     3     2     1   \n",
      "...      ...       ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
      "2606     ...         2     2     1     3     0     3     0     2     2   \n",
      "2607     ...         3     1     1     3     0     2     3     3     2   \n",
      "2608     ...         3     4     1     0     2     2     3     3     2   \n",
      "2609     ...         1     4     1     1     2     3     0     1     2   \n",
      "2610     ...         1     1     1     3     2     1     0     4     2   \n",
      "2611     ...         2     1     0     2     2     1     1     2     2   \n",
      "2612     ...         2     1     1     1     2     3     0     1     2   \n",
      "2613     ...         2     2     2     4     3     3     3     4     2   \n",
      "2614     ...         3     1     1     0     1     2     0     1     2   \n",
      "2615     ...         2     1     1     3     1     2     0     1     2   \n",
      "2616     ...         2     4     1     1     2     1     0     4     2   \n",
      "2617     ...         1     3     0     1     0     2     0     2     1   \n",
      "2618     ...         3     4     1     3     2     3     3     3     2   \n",
      "2619     ...         2     1     1     0     2     1     0     0     1   \n",
      "2620     ...         0     1     1     0     2     2     1     1     1   \n",
      "2621     ...         1     1     1     0     2     2     1     0     1   \n",
      "2622     ...         3     1     1     1     2     2     1     1     2   \n",
      "2623     ...         1     2     1     3     2     1     0     1     1   \n",
      "2624     ...         2     0     0     0     2     1     0     0     2   \n",
      "2625     ...         3     4     1     1     2     2     0     2     2   \n",
      "2626     ...         1     1     1     2     2     2     1     3     2   \n",
      "2627     ...         3     1     1     3     2     3     0     3     2   \n",
      "2628     ...         1     2     1     3     2     2     0     4     2   \n",
      "2629     ...         3     4     1     3     2     3     1     3     2   \n",
      "2630     ...         3     1     1     0     2     1     1     2     2   \n",
      "2631     ...         1     2     1     0     0     2     0     4     2   \n",
      "2632     ...         1     4     1     3     2     3     0     2     2   \n",
      "2633     ...         0     1     2     4     2     2     2     2     2   \n",
      "2634     ...         2     1     1     1     2     2     1     0     2   \n",
      "2635     ...         1     0     1     4     0     2     3     2     2   \n",
      "\n",
      "      target_new  \n",
      "0              1  \n",
      "1              1  \n",
      "2              0  \n",
      "3              1  \n",
      "4              0  \n",
      "5              1  \n",
      "6              0  \n",
      "7              0  \n",
      "8              0  \n",
      "9              0  \n",
      "10             0  \n",
      "11             0  \n",
      "12             1  \n",
      "13             0  \n",
      "14             1  \n",
      "15             0  \n",
      "16             0  \n",
      "17             0  \n",
      "18             0  \n",
      "19             0  \n",
      "20             1  \n",
      "21             0  \n",
      "22             0  \n",
      "23             0  \n",
      "24             0  \n",
      "25             0  \n",
      "26             0  \n",
      "27             0  \n",
      "28             0  \n",
      "29             0  \n",
      "...          ...  \n",
      "2606           0  \n",
      "2607           0  \n",
      "2608           0  \n",
      "2609           0  \n",
      "2610           0  \n",
      "2611           0  \n",
      "2612           0  \n",
      "2613           0  \n",
      "2614           0  \n",
      "2615           1  \n",
      "2616           0  \n",
      "2617           0  \n",
      "2618           0  \n",
      "2619           0  \n",
      "2620           0  \n",
      "2621           0  \n",
      "2622           1  \n",
      "2623           1  \n",
      "2624           0  \n",
      "2625           0  \n",
      "2626           0  \n",
      "2627           0  \n",
      "2628           0  \n",
      "2629           0  \n",
      "2630           1  \n",
      "2631           0  \n",
      "2632           1  \n",
      "2633           1  \n",
      "2634           1  \n",
      "2635           0  \n",
      "\n",
      "[2636 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "df_hum = pd.read_csv(r'D:\\sem1\\intro to ml\\project 2\\HumanObserved-Dataset\\HumanObserved-Dataset\\HumanObserved-Features-Data\\HumanObserved-Features-Data.csv')\n",
    "df_hum_same = pd.read_csv(r'D:\\sem1\\intro to ml\\project 2\\HumanObserved-Dataset\\HumanObserved-Dataset\\HumanObserved-Features-Data\\diffn_pairs.csv')\n",
    "df_hum_diff = pd.read_csv(r'D:\\sem1\\intro to ml\\project 2\\HumanObserved-Dataset\\HumanObserved-Dataset\\HumanObserved-Features-Data\\same_pairs.csv')\n",
    "#df_hum_same = np.array_split(df_hum_same1,395) \n",
    "#df_hum_diff = np.array_split(df_hum_diff1,790)\n",
    "#print(df_hum_diff)\n",
    "frames1 = [df_hum_same,df_hum_diff]\n",
    "df_hum.drop(df_hum.columns[[0]], axis=1,inplace=True)\n",
    "df_output1 = pd.concat(frames1)\n",
    "#col_hum = ['img_id_A','img_id_B','t']\n",
    "#df.rename(columns ={39: ‘col40’}, inplace =True\n",
    "df_o1 = df_output1.rename(index = str, columns ={\"img_id_A\" : \"img_id\"})\n",
    "con_num1 = pd.merge(df_o1, df_hum, on='img_id')\n",
    "#print(con_num1)\n",
    "con_num3 = con_num1.rename(index = str, columns ={\"img_id\" : \"img_id_A\"})\n",
    "#df_o2 = df_o1.rename(index = str, columns ={\"img_id\" : \"img_id_A\"})\n",
    "\n",
    "df_o3 = con_num3.rename(index = str, columns ={\"img_id_B\" : \"img_id\"})\n",
    "\n",
    "con_num2 = pd.merge(df_o3, df_hum, on='img_id')\n",
    "\n",
    "final_con = con_num2.rename(index = str, columns ={\"img_id\" : \"img_id_B\"})\n",
    "\n",
    "final_con.insert(21,'target_new',0)\n",
    "\n",
    "final_con.loc[:,'target_new'] = final_con['target']\n",
    "\n",
    "final_con.drop(final_con.columns[[2]], axis=1,inplace=True)\n",
    "final_con.sort_values('target_new', inplace = True,ascending = False)\n",
    "#dfs of 0 and 1\n",
    "df_o = final_con[final_con['target_new'] == 0]\n",
    "\n",
    "df_1 = final_con[final_con['target_new'] == 1]\n",
    "dfo=df_o.sample(n=1845)\n",
    "#print(dfo)\n",
    "\n",
    "frames2 = [df_1,dfo]\n",
    "final_data1 = pd.concat(frames2)\n",
    "#print(final_set)\n",
    "tardf = final_con[['target_new']].copy()\n",
    "\n",
    "final_data = final_data1.sample(frac=1, axis=0).reset_index(drop=True)\n",
    "final_data.to_csv(r\"C:\\Users\\Jayanth\\Downloads\\final-human.csv\")\n",
    "print(final_data)\n",
    "con_copy = final_con.copy()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTargetVector(filePath):\n",
    "    t = []\n",
    "    with open(filePath, 'rU') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:  \n",
    "            t.append(int(row[0]))\n",
    "    #print(\"Raw Training Generated..\")\n",
    "    return t\n",
    "\n",
    "# put the data of csv file to matrix form\n",
    "def GenerateRawData(filePath):    \n",
    "    dataMatrix = [] \n",
    "    dataMatrix1 = []\n",
    "    with open(filePath, 'rU') as fi:\n",
    "        reader = csv.reader(fi)\n",
    "        for row in reader:\n",
    "            dataRow = []\n",
    "            for column in row:\n",
    "                dataRow.append(float(column))\n",
    "            dataMatrix.append(dataRow)\n",
    "            \n",
    "    #dataMatrix1 = np.transpose(dataMatrix)     \n",
    "    #print (\"Data Matrix Generated..\")\n",
    "    dataMatrix = np.transpose(dataMatrix) \n",
    "    return dataMatrix\n",
    "# Training percent is set (which can be changed for tuning)\n",
    "# target list is made up from the data sets passed\n",
    "def GenerateTrainingTarget(rawTraining,TrainingPercent = 80):\n",
    "    TrainingLen = int(math.ceil(len(rawTraining)*(TrainingPercent*0.01)))\n",
    "    t           = rawTraining[:TrainingLen]\n",
    "    #print(str(TrainingPercent) + \"% Training Target Generated..\")\n",
    "    return t\n",
    "# generate the data matrix with the 80% training set\n",
    "\n",
    "def GenerateTrainingDataMatrix(rawData, TrainingPercent = 80):\n",
    "    T_len = int(math.ceil(len(rawData[0])*0.01*TrainingPercent))\n",
    "    d2 = rawData[:,0:T_len]\n",
    "    #print(str(TrainingPercent) + \"% Training Data Generated..\")\n",
    "    return d2\n",
    "#data being made for validation of the model which is 10% of the dataset\n",
    "\n",
    "def GenerateValData(rawData, ValPercent, TrainingCount): \n",
    "    valSize = int(math.ceil(len(rawData[0])*ValPercent*0.01))\n",
    "    V_End = TrainingCount + valSize\n",
    "    dataMatrix = rawData[:,TrainingCount+1:V_End]\n",
    "    #print (str(ValPercent) + \"% Val Data Generated..\")  \n",
    "    return dataMatrix\n",
    "def GenerateValTargetVector(rawData, ValPercent, TrainingCount): \n",
    "    valSize = int(math.ceil(len(rawData)*ValPercent*0.01))\n",
    "    V_End = TrainingCount + valSize\n",
    "    t =rawData[TrainingCount+1:V_End]\n",
    "    #print (str(ValPercent) + \"% Val Target Data Generated..\")\n",
    "    return t\n",
    "\n",
    "#BIGSIGMA : generates a covariance matrix.Each value will be covariance of a element with i-th and j-th elements of an random vector\n",
    "#this is used to regularize\n",
    "def GenerateBigSigma(Data, MuMatrix,TrainingPercent):\n",
    "    BigSigma    = np.zeros((len(Data),len(Data)))\n",
    "    DataT       = np.transpose(Data)\n",
    "    print(DataT)\n",
    "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01))        \n",
    "    varVect     = []\n",
    "    for i in range(0,len(DataT[0])):\n",
    "        vct = []\n",
    "        for j in range(0,int(TrainingLen)):\n",
    "            vct.append(Data[i][j])    \n",
    "        varVect.append(np.var(vct))\n",
    "    \n",
    "    for j in range(len(Data)):\n",
    "        BigSigma[j][j] = varVect[j] + 0.2\n",
    "    \n",
    "    BigSigma = np.dot(200,BigSigma)\n",
    "    ##print (\"BigSigma Generated..\")\n",
    "    return BigSigma\n",
    "\n",
    "def GetScalar(DataRow,MuRow, BigSigInv):  \n",
    "    R = np.subtract(DataRow,MuRow)\n",
    "    T = np.dot(BigSigInv,np.transpose(R))  \n",
    "    L = np.dot(R,T)\n",
    "    return L\n",
    "#gets guassian radial basis function\n",
    "def GetRadialBasisOut(DataRow,MuRow, BigSigInv):    \n",
    "    phi_x = math.exp(-0.5*GetScalar(DataRow,MuRow,BigSigInv))\n",
    "    return phi_x\n",
    "#This generates the design matrix, features of the original input\n",
    "def GetPhiMatrix(Data, MuMatrix, BigSigma, TrainingPercent = 80):\n",
    "    DataT = np.transpose(Data)\n",
    "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01))         \n",
    "    PHI = np.zeros((int(TrainingLen),len(MuMatrix))) \n",
    "    BigSigInv = np.linalg.inv(BigSigma)\n",
    "    #print(BigSigInv.shape)\n",
    "    for  C in range(0,len(MuMatrix)):\n",
    "        for R in range(0,int(TrainingLen)):\n",
    "            PHI[R][C] = GetRadialBasisOut(DataT[R], MuMatrix[C], BigSigInv)\n",
    "    #print (\"PHI Generated..\")\n",
    "    return PHI\n",
    "# to generate the weight matrix\n",
    "def GetWeightsClosedForm(PHI, T, Lambda):\n",
    "    Lambda_I = np.identity(len(PHI[0]))\n",
    "    for i in range(0,len(PHI[0])):\n",
    "        Lambda_I[i][i] = Lambda\n",
    "    PHI_T       = np.transpose(PHI)\n",
    "    PHI_SQR     = np.dot(PHI_T,PHI)\n",
    "    PHI_SQR_LI  = np.add(Lambda_I,PHI_SQR)\n",
    "    PHI_SQR_INV = np.linalg.inv(PHI_SQR_LI)\n",
    "    INTER       = np.dot(PHI_SQR_INV, PHI_T)\n",
    "    W           = np.dot(INTER, T)\n",
    "    ##print (\"Training Weights Generated..\")\n",
    "    return W\n",
    "#gets the linear regression values\n",
    "def GetValTest(VAL_PHI,W):\n",
    "    Y = np.dot(W,np.transpose(VAL_PHI))\n",
    "    ##print (\"Test Out Generated..\")\n",
    "    return Y\n",
    "#function to get the root mean square error\n",
    "def GetErms(VAL_TEST_OUT,ValDataAct):\n",
    "    sum = 0.0\n",
    "    t=0\n",
    "    accuracy = 0.0\n",
    "    counter = 0\n",
    "    val = 0.0\n",
    "    for i in range (0,len(VAL_TEST_OUT)):\n",
    "        sum = sum + math.pow((ValDataAct[i] - VAL_TEST_OUT[i]),2)\n",
    "        if(int(np.around(VAL_TEST_OUT[i], 0)) == ValDataAct[i]):\n",
    "            counter+=1\n",
    "    accuracy = (float((counter*100))/float(len(VAL_TEST_OUT)))\n",
    "    ##print (\"Accuracy Generated..\")\n",
    "    ##print (\"Validation E_RMS : \" + str(math.sqrt(sum/len(VAL_TEST_OUT))))\n",
    "    return (str(accuracy) + ',' +  str(math.sqrt(sum/len(VAL_TEST_OUT))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting final data into training and testing \n",
    "train1 = final_data.drop(final_data.columns[[0]], axis=1)\n",
    "train2 = train1.drop(train1.columns[[0]], axis=1)\n",
    "train2.drop(train2.columns[[18]], axis=1,inplace = True)\n",
    "train3 = train2[(train2.T != 0).any()]\n",
    "#print(train3)\n",
    "tar_ma = final_data[['target_new']].copy()\n",
    "train3.to_csv(r\"D:\\sem1\\intro to ml\\project 2\\final-human.csv\", header=False,index =False)\n",
    "tar_ma.to_csv(r\"D:\\sem1\\intro to ml\\project 2\\target.csv\", header=False,index = False)\n",
    "\n",
    "#print(train2)\n",
    "train=train3.iloc[:2110]\n",
    "vali = train3.iloc[2110:2374]\n",
    "test = train3.iloc[2374:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 2636)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayanth\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: 'U' mode is deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Jayanth\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: 'U' mode is deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "RawTarget = GetTargetVector(r\"D:\\sem1\\intro to ml\\project 2\\target.csv\")\n",
    "RawData   = GenerateRawData(r\"D:\\sem1\\intro to ml\\project 2\\final-human.csv\")\n",
    "print(RawData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingTarget = np.array(GenerateTrainingTarget(RawTarget,TrainingPercent))\n",
    "TrainingData   = GenerateTrainingDataMatrix(RawData,TrainingPercent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValDataAct = np.array(GenerateValTargetVector(RawTarget,ValidationPercent, (len(TrainingTarget))))\n",
    "ValData    = GenerateValData(RawData,ValidationPercent, (len(TrainingTarget)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 2636)\n"
     ]
    }
   ],
   "source": [
    "TestDataAct = np.array(GenerateValTargetVector(RawTarget,TestPercent, (len(TrainingTarget)+len(ValDataAct))))\n",
    "TestData = GenerateValData(RawData,TestPercent, (len(TrainingTarget)+len(ValDataAct)))\n",
    "print(RawData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 2636)\n",
      "[[2. 0. 1. ... 0. 1. 2.]\n",
      " [1. 4. 1. ... 0. 4. 2.]\n",
      " [3. 1. 1. ... 0. 2. 2.]\n",
      " ...\n",
      " [3. 4. 2. ... 2. 2. 2.]\n",
      " [3. 1. 1. ... 1. 0. 2.]\n",
      " [1. 2. 1. ... 3. 2. 2.]]\n",
      "(18, 18)\n",
      "(18, 2636)\n"
     ]
    }
   ],
   "source": [
    "M=18\n",
    "kmeans = KMeans(n_clusters=M, random_state=0).fit(np.transpose(TrainingData))\n",
    "Mu = kmeans.cluster_centers_\n",
    "print(RawData.shape)\n",
    "ErmsArr = []\n",
    "AccuracyArr = []\n",
    "\n",
    "BigSigma     = GenerateBigSigma(RawData, Mu, TrainingPercent)\n",
    "#print(BigSigma.shape)\n",
    "print(Mu.shape)\n",
    "print(RawData.shape)\n",
    "TRAINING_PHI = GetPhiMatrix(RawData, Mu, BigSigma, TrainingPercent)\n",
    "W            = GetWeightsClosedForm(TRAINING_PHI,TrainingTarget,(C_Lambda)) \n",
    "TEST_PHI     = GetPhiMatrix(TestData, Mu, BigSigma, 100) \n",
    "VAL_PHI      = GetPhiMatrix(ValData, Mu, BigSigma, 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W_Now        = np.dot(220, W)\n",
    "# hyperparameter \n",
    "La           = 2\n",
    "#lamda\n",
    "#hyperparameter \n",
    "learningRate = 0.1\n",
    "#0.1 test = 0.64\n",
    "#0.5 test =\n",
    "L_Erms_Val   = []\n",
    "L_Erms_TR    = []\n",
    "L_Erms_Test  = []\n",
    "W_Mat        = []\n",
    "acc  = []\n",
    "L_Erms_Acc = []\n",
    "#L_Erms_Val_acc = []\n",
    "\n",
    "\n",
    "for i in range(0,400):\n",
    "    #go through the phi matrix rows for the epochs which we set\n",
    "    #print ('---------Iteration: ' + str(i) + '--------------')\n",
    "    \n",
    "    Delta_E_D     = -np.dot((TrainingTarget[i] - np.dot(np.transpose(W_Now),TRAINING_PHI[i])),TRAINING_PHI[i])\n",
    "    La_Delta_E_W  = np.dot(La,W_Now)\n",
    "    Delta_E       = np.add(Delta_E_D,La_Delta_E_W)    \n",
    "    Delta_W       = -np.dot(learningRate,Delta_E)\n",
    "    # update weights\n",
    "    \n",
    "    W_T_Next      = W_Now + Delta_W\n",
    "    W_Now         = W_T_Next\n",
    "    \n",
    "    #-----------------TrainingData Accuracy---------------------#\n",
    "    TR_TEST_OUT   = GetValTest(TRAINING_PHI,W_T_Next) \n",
    "    Erms_TR       = GetErms(TR_TEST_OUT,TrainingTarget)\n",
    "    \n",
    "    L_Erms_TR.append(float(Erms_TR.split(',')[1]))\n",
    "    \n",
    "    #-----------------ValidationData Accuracy---------------------#\n",
    "    VAL_TEST_OUT  = GetValTest(VAL_PHI,W_T_Next) \n",
    "    Erms_Val      = GetErms(VAL_TEST_OUT,ValDataAct)\n",
    "    L_Erms_Val.append(float(Erms_Val.split(',')[1]))\n",
    "    \n",
    "    #-----------------TestingData Accuracy---------------------#\n",
    "    TEST_OUT      = GetValTest(TEST_PHI,W_T_Next) \n",
    "    Erms_Test = GetErms(TEST_OUT,TestDataAct)\n",
    "    acc.append(float(Erms_TR.split(',')[0]))\n",
    "    L_Erms_Test.append(float(Erms_Test.split(',')[1]))\n",
    "    \n",
    "    L_Erms_Acc.append(float(Erms_Test.split(',')[0]))\n",
    "\n",
    "#plot the graph\n",
    "plt.plot([m for m in range(0,400)], L_Erms_Test, linewidth = 0.30);\n",
    "plt.xlabel(\"EPOCH of Dataset\")\n",
    "plt.ylabel(\"RMS- TESTING\")\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "#df = pd.DataFrame(Erms_Test)\n",
    "#df.plot(subplots=True, grid=True, figsize=(10,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "E_rms Training   = 0.4577\n",
      "E_rms Validation = 0.47673\n",
      "E_rms Testing    = 0.43316\n",
      "Testing Accuracy = 74.90494\n"
     ]
    }
   ],
   "source": [
    "print (\"\")\n",
    "print (\"E_rms Training   = \" + str(np.around(min(L_Erms_TR),5)))\n",
    "print (\"E_rms Validation = \" + str(np.around(min(L_Erms_Val),5)))\n",
    "print (\"E_rms Testing    = \" + str(np.around(min(L_Erms_Test),5)))\n",
    "print (\"Testing Accuracy = \" + str(np.around(max(L_Erms_Acc),5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
